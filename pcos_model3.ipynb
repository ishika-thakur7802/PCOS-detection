{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishika-thakur7802/PCOS-detection/blob/main/pcos_model3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntLdi2z_dfsI",
        "outputId": "1285356f-c7a1-49d5-e090-88c016918814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FXd_8J6wq5l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Add, Multiply, Activation, Reshape, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es2vRwHRwmoe"
      },
      "outputs": [],
      "source": [
        "# Data processing\n",
        "img_data_list = []\n",
        "labels = []\n",
        "\n",
        "# Load data for class 0\n",
        "data_path_0 = '/content/drive/MyDrive/PCOS-Hack/Dest_folder/0'\n",
        "for dataset in os.listdir(data_path_0):\n",
        "    input_img = cv2.imread(os.path.join(data_path_0, dataset))\n",
        "    if input_img is None:\n",
        "        print(f\"Warning: Image {dataset} could not be loaded.\")\n",
        "        continue\n",
        "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
        "    labels.append(0)  # Label for class 0\n",
        "    input_img_resize = cv2.resize(input_img, (224, 224))\n",
        "    input_img_resize = cv2.normalize(input_img_resize, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    img_data_list.append(input_img_resize)\n",
        "\n",
        "# Load data for class 1\n",
        "data_path_1 = '/content/drive/MyDrive/PCOS-Hack/Dest_folder/1_augmented'\n",
        "for dataset in os.listdir(data_path_1):\n",
        "    input_img = cv2.imread(os.path.join(data_path_1, dataset))\n",
        "    if input_img is None:\n",
        "        print(f\"Warning: Image {dataset} could not be loaded.\")\n",
        "        continue\n",
        "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
        "    labels.append(1)  # Label for class 1\n",
        "    input_img_resize = cv2.resize(input_img, (224, 224))\n",
        "    input_img_resize = cv2.normalize(input_img_resize, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    img_data_list.append(input_img_resize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_O5RvdDOxEE"
      },
      "outputs": [],
      "source": [
        "# img_data_list = []\n",
        "# labels = []\n",
        "\n",
        "# input_img = cv2.imread('/content/f1.jpeg')\n",
        "# input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
        "# labels.append(1)  # Label for class 1\n",
        "# input_img_resize = cv2.resize(input_img, (224, 224))\n",
        "\n",
        "# input_img_resize = cv2.normalize(input_img_resize, None, 0, 255, cv2.NORM_MINMAX)\n",
        "# img_data_list.append(input_img_resize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHHtpic91xWl",
        "outputId": "5a41e589-cb0c-463e-8268-05f4ea885edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 5006\n",
            "Number of labels: 5006\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of images: {len(img_data_list)}')\n",
        "print(f'Number of labels: {len(labels)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVZycXtUwx-V",
        "outputId": "d937ebfe-3e7a-450c-85b6-9767cfb96725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image data shape: (5006, 224, 224, 3)\n",
            "Labels shape: (5006,)\n"
          ]
        }
      ],
      "source": [
        "# Convert lists to arrays\n",
        "img_data = np.array(img_data_list)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f'Image data shape: {img_data.shape}')\n",
        "print(f'Labels shape: {labels.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx-Nj2yPw4tH"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the labels\n",
        "labels = to_categorical(labels, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9FURIy531Sj",
        "outputId": "b7a64e57-7adb-4a6e-8a43-ae6d5e3be925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels shape after one-hot encoding: (5006, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'Labels shape after one-hot encoding: {labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33pVl11Yw9Dl"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(img_data, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnODfxH_36iQ",
        "outputId": "863a7f97-48bf-4e8b-8a9d-b0c05843c9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape after split: (4004, 224, 224, 3)\n",
            "y_train shape after split: (4004, 2)\n",
            "X_val shape after split: (1002, 224, 224, 3)\n",
            "y_val shape after split: (1002, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'X_train shape after split: {X_train.shape}')\n",
        "print(f'y_train shape after split: {y_train.shape}')\n",
        "print(f'X_val shape after split: {X_val.shape}')\n",
        "print(f'y_val shape after split: {y_val.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbUYlFWu1RPB"
      },
      "outputs": [],
      "source": [
        "assert X_train.shape[0] == y_train.shape[0], \"Mismatch in number of samples between X_train and y_train\"\n",
        "assert X_val.shape[0] == y_val.shape[0], \"Mismatch in number of samples between X_val and y_val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnKdB1ZEPTHc"
      },
      "outputs": [],
      "source": [
        "# X_train = img_data[0]\n",
        "# y_train = labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quzKn9WuZNED"
      },
      "outputs": [],
      "source": [
        "def cam_block(x):\n",
        "    print(\"Input shape:\", x.shape)\n",
        "\n",
        "    # Apply convolution with dilation rates\n",
        "    dilated_1 = Conv2D(x.shape[-1], (3, 3), activation='relu', dilation_rate=1, padding='same')(x)\n",
        "    print(\"dilated_1 shape:\", dilated_1.shape)\n",
        "\n",
        "    dilated_2 = Conv2D(x.shape[-1], (3, 3), activation='relu', dilation_rate=2, padding='same')(x)\n",
        "    print(\"dilated_2 shape:\", dilated_2.shape)\n",
        "\n",
        "    dilated_3 = Conv2D(x.shape[-1], (3, 3), activation='relu', dilation_rate=3, padding='same')(x)\n",
        "    print(\"dilated_3 shape:\", dilated_3.shape)\n",
        "\n",
        "    # Element-wise add conv_1 and conv_2\n",
        "    add_result = Add()([dilated_1, dilated_2])\n",
        "    print(\"add_result shape:\", add_result.shape)\n",
        "\n",
        "    # Element-wise multiply conv_2 and conv_3\n",
        "    mul_result = Multiply()([dilated_2, dilated_3])\n",
        "    print(\"mul_result shape:\", mul_result.shape)\n",
        "\n",
        "    # 1x1 convolutions on the results\n",
        "    conv_add = Conv2D(x.shape[-1], (1, 1), activation='relu', padding='same')(add_result)\n",
        "    print(\"conv_add shape:\", conv_add.shape)\n",
        "    conv_mul = Conv2D(x.shape[-1], (1, 1), activation='relu', padding='same')(mul_result)\n",
        "    print(\"conv_mul shape:\", conv_mul.shape)\n",
        "\n",
        "    # Apply Global Average Pooling and Global Max Pooling\n",
        "    gap = GlobalAveragePooling2D()(conv_add)\n",
        "    print(\"gap shape:\", gap.shape)\n",
        "    gmp = GlobalMaxPooling2D()(conv_mul)\n",
        "    print(\"gmp shape:\", gmp.shape)\n",
        "\n",
        "    # Multiply the pooled outputs\n",
        "    combined = Multiply()([gap, gmp])\n",
        "    print(\"combined shape:\", combined.shape)\n",
        "\n",
        "    # Pass through sigmoid activation function\n",
        "    sigmoid_output = Activation('sigmoid')(combined)\n",
        "    print(\"sigmoid_output shape:\", sigmoid_output.shape)\n",
        "\n",
        "    # Multiply with the initial input\n",
        "    multiplied_output = Multiply()([x, sigmoid_output])\n",
        "    print(\"multiplied_output shape:\", multiplied_output.shape)\n",
        "\n",
        "    # Element-wise add the multiplied output to the initial input\n",
        "    final_output = Add()([x, multiplied_output])\n",
        "    print(\"final_output shape:\", final_output.shape)\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IigCXnbt94QK",
        "outputId": "af7aee7e-c92b-46f4-eca2-3fa4eff590c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (None, 224, 224, 32)\n",
            "dilated_1 shape: (None, 224, 224, 32)\n",
            "dilated_2 shape: (None, 224, 224, 32)\n",
            "dilated_3 shape: (None, 224, 224, 32)\n",
            "add_result shape: (None, 224, 224, 32)\n",
            "mul_result shape: (None, 224, 224, 32)\n",
            "conv_add shape: (None, 224, 224, 32)\n",
            "conv_mul shape: (None, 224, 224, 32)\n",
            "gap shape: (None, 32)\n",
            "gmp shape: (None, 32)\n",
            "combined shape: (None, 32)\n",
            "sigmoid_output shape: (None, 32)\n",
            "multiplied_output shape: (None, 224, 224, 32)\n",
            "final_output shape: (None, 224, 224, 32)\n",
            "Input shape: (None, 224, 224, 32)\n",
            "dilated_1 shape: (None, 224, 224, 32)\n",
            "dilated_2 shape: (None, 224, 224, 32)\n",
            "dilated_3 shape: (None, 224, 224, 32)\n",
            "add_result shape: (None, 224, 224, 32)\n",
            "mul_result shape: (None, 224, 224, 32)\n",
            "conv_add shape: (None, 224, 224, 32)\n",
            "conv_mul shape: (None, 224, 224, 32)\n",
            "gap shape: (None, 32)\n",
            "gmp shape: (None, 32)\n",
            "combined shape: (None, 32)\n",
            "sigmoid_output shape: (None, 32)\n",
            "multiplied_output shape: (None, 224, 224, 32)\n",
            "final_output shape: (None, 224, 224, 32)\n",
            "Input shape: (None, 224, 224, 64)\n",
            "dilated_1 shape: (None, 224, 224, 64)\n",
            "dilated_2 shape: (None, 224, 224, 64)\n",
            "dilated_3 shape: (None, 224, 224, 64)\n",
            "add_result shape: (None, 224, 224, 64)\n",
            "mul_result shape: (None, 224, 224, 64)\n",
            "conv_add shape: (None, 224, 224, 64)\n",
            "conv_mul shape: (None, 224, 224, 64)\n",
            "gap shape: (None, 64)\n",
            "gmp shape: (None, 64)\n",
            "combined shape: (None, 64)\n",
            "sigmoid_output shape: (None, 64)\n",
            "multiplied_output shape: (None, 224, 224, 64)\n",
            "final_output shape: (None, 224, 224, 64)\n",
            "Input shape: (None, 224, 224, 64)\n",
            "dilated_1 shape: (None, 224, 224, 64)\n",
            "dilated_2 shape: (None, 224, 224, 64)\n",
            "dilated_3 shape: (None, 224, 224, 64)\n",
            "add_result shape: (None, 224, 224, 64)\n",
            "mul_result shape: (None, 224, 224, 64)\n",
            "conv_add shape: (None, 224, 224, 64)\n",
            "conv_mul shape: (None, 224, 224, 64)\n",
            "gap shape: (None, 64)\n",
            "gmp shape: (None, 64)\n",
            "combined shape: (None, 64)\n",
            "sigmoid_output shape: (None, 64)\n",
            "multiplied_output shape: (None, 224, 224, 64)\n",
            "final_output shape: (None, 224, 224, 64)\n",
            "Input shape: (None, 224, 224, 64)\n",
            "dilated_1 shape: (None, 224, 224, 64)\n",
            "dilated_2 shape: (None, 224, 224, 64)\n",
            "dilated_3 shape: (None, 224, 224, 64)\n",
            "add_result shape: (None, 224, 224, 64)\n",
            "mul_result shape: (None, 224, 224, 64)\n",
            "conv_add shape: (None, 224, 224, 64)\n",
            "conv_mul shape: (None, 224, 224, 64)\n",
            "gap shape: (None, 64)\n",
            "gmp shape: (None, 64)\n",
            "combined shape: (None, 64)\n",
            "sigmoid_output shape: (None, 64)\n",
            "multiplied_output shape: (None, 224, 224, 64)\n",
            "final_output shape: (None, 224, 224, 64)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "# Define the main model with CAM blocks\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# First convolutional layer with dilation rate 1\n",
        "x1 = Conv2D(32, (3, 3), activation='relu', dilation_rate=1, padding='same')(inputs)\n",
        "\n",
        "# Second convolutional layer with dilation rate 2\n",
        "x2 = Conv2D(32, (3, 3), activation='relu', dilation_rate=2, padding='same')(x1)\n",
        "\n",
        "# Third convolutional layer with dilation rate 3\n",
        "x3 = Conv2D(64, (3, 3), activation='relu', dilation_rate=3, padding='same')(x2)\n",
        "\n",
        "# Fourth convolutional layer with dilation rate 4\n",
        "x4 = Conv2D(64, (3, 3), activation='relu', dilation_rate=4, padding='same')(x3)\n",
        "\n",
        "# Fifth convolutional layer with dilation rate 5\n",
        "x5 = Conv2D(64, (3, 3), activation='relu', dilation_rate=5, padding='same')(x4)\n",
        "\n",
        "# Apply the CAM block to each convolutional output\n",
        "cam_output1 = cam_block(x1)\n",
        "cam_output2 = cam_block(x2)\n",
        "cam_output3 = cam_block(x3)\n",
        "cam_output4 = cam_block(x4)\n",
        "cam_output5 = cam_block(x5)\n",
        "\n",
        "# Apply Global Max Pooling to each CAM output\n",
        "gmp1 = GlobalMaxPooling2D()(cam_output1)\n",
        "gmp2 = GlobalMaxPooling2D()(cam_output2)\n",
        "gmp3 = GlobalMaxPooling2D()(cam_output3)\n",
        "gmp4 = GlobalMaxPooling2D()(cam_output4)\n",
        "gmp5 = GlobalMaxPooling2D()(cam_output5)\n",
        "\n",
        "# Feature aggregation layer\n",
        "aggregated_features = Concatenate()([gmp1, gmp2, gmp3, gmp4, gmp5])\n",
        "\n",
        "# Add a Dense layer with 32 units\n",
        "dense_features = Dense(32, activation='relu')(aggregated_features)\n",
        "\n",
        "# Add another Dense layer with 2 units for classification\n",
        "dense_output = Dense(num_classes, activation='softmax')(dense_features)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs, dense_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH8q4gz16Kig"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Clear the session to free up memory\n",
        "K.clear_session()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFpbBu9PtvoY",
        "outputId": "b064cad1-5853-4148-8f48-5942f0467414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4004, 224, 224, 3)\n",
            "y_train shape: (4004, 2)\n",
            "X_val shape: (1002, 224, 224, 3)\n",
            "y_val shape: (1002, 2)\n",
            "Epoch 1/50\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - accuracy: 0.6735 - loss: 7.0671 - val_accuracy: 0.7445 - val_loss: 0.7335\n",
            "Epoch 2/50\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 937ms/step - accuracy: 0.7754 - loss: 0.6568 - val_accuracy: 0.7375 - val_loss: 0.5553\n",
            "Epoch 3/50\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 937ms/step - accuracy: 0.8082 - loss: 0.4650 - val_accuracy: 0.8703 - val_loss: 0.3654\n",
            "Epoch 4/50\n",
            "\u001b[1m 90/251\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 882ms/step - accuracy: 0.8284 - loss: 0.3750"
          ]
        }
      ],
      "source": [
        "# Check the shapes of the training and validation data\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'X_val shape: {X_val.shape}')\n",
        "print(f'y_val shape: {y_val.shape}')\n",
        "\n",
        "# The shapes should match in the first dimension (number of samples)\n",
        "# Ensure all arrays contain the same number of samples\n",
        "assert X_train.shape[0] == y_train.shape[0], \"Mismatch in number of samples between X_train and y_train\"\n",
        "assert X_val.shape[0] == y_val.shape[0], \"Mismatch in number of samples between X_val and y_val\"\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=16,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n",
        "# Plot the training and validation accuracy and loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMRRnLWachVW"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/PCOS-Hack/models/model_50.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}